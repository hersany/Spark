{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "checked-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adult-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "joint-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/navarra/anaconda3/spark/Exercise Files/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caring-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('json').load(data_path + '/utlization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legislative-choir",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smooth-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "raising-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  500000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT count(*) \\\n",
    "                    FROM utilization')\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "facial-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  239659|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT count(*) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70')\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dental-gallery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|server_id|count(1)|\n",
      "+---------+--------+\n",
      "|      112|    7425|\n",
      "|      113|    9418|\n",
      "|      130|    2891|\n",
      "|      126|    6365|\n",
      "|      149|    8288|\n",
      "|      110|    2826|\n",
      "|      136|    4316|\n",
      "|      144|    6220|\n",
      "|      116|    1167|\n",
      "|      145|    9304|\n",
      "|      143|     144|\n",
      "|      107|    5646|\n",
      "|      146|    7072|\n",
      "|      103|    8744|\n",
      "|      139|    7383|\n",
      "|      114|    2128|\n",
      "|      115|    5284|\n",
      "|      104|    7366|\n",
      "|      120|    2733|\n",
      "|      128|    3719|\n",
      "+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id, count(*) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id')\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "functional-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|server_id|counts|\n",
      "+---------+------+\n",
      "|      101|  9808|\n",
      "|      113|  9418|\n",
      "|      145|  9304|\n",
      "|      103|  8744|\n",
      "|      102|  8586|\n",
      "|      133|  8583|\n",
      "|      108|  8375|\n",
      "|      149|  8288|\n",
      "|      137|  8248|\n",
      "|      148|  8027|\n",
      "|      123|  7918|\n",
      "|      118|  7913|\n",
      "|      112|  7425|\n",
      "|      139|  7383|\n",
      "|      104|  7366|\n",
      "|      142|  7084|\n",
      "|      121|  7084|\n",
      "|      146|  7072|\n",
      "|      126|  6365|\n",
      "|      144|  6220|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id, count(*) AS counts \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id \\\n",
    "                    ORDER BY counts DESC')\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "colored-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------+------------------+\n",
      "|server_id|min(session_count)|avg(session_count)|max(session_count)|\n",
      "+---------+------------------+------------------+------------------+\n",
      "|      112|                71| 83.54505050505051|                97|\n",
      "|      113|                71| 86.96262476109577|               103|\n",
      "|      130|                71| 75.50501556554825|                80|\n",
      "|      126|                71| 81.56150824823253|                93|\n",
      "|      149|                71|  84.9612693050193|                99|\n",
      "|      110|                71| 75.46709129511677|                80|\n",
      "|      136|                71| 77.96200185356813|                85|\n",
      "|      144|                71| 81.38472668810289|                92|\n",
      "|      116|                71| 72.61953727506426|                75|\n",
      "|      145|                71| 86.97732158211522|               103|\n",
      "|      143|                71|              71.0|                71|\n",
      "|      107|                71| 80.34945093871768|                90|\n",
      "|      146|                71| 82.95093325791855|                95|\n",
      "|      103|                71| 85.76372369624886|               101|\n",
      "|      139|                71| 83.32710280373831|                96|\n",
      "|      114|                71| 74.17951127819549|                78|\n",
      "|      115|                71| 79.69776684330053|                89|\n",
      "|      104|                71| 83.34604941623677|                96|\n",
      "|      120|                71| 75.37321624588364|                80|\n",
      "|      128|                71| 76.93385318634041|                83|\n",
      "+---------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id, min(session_count), avg(session_count), max(session_count) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id')\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "failing-productivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+----------------------------+------------------+\n",
      "|server_id|min(session_count)|round(avg(session_count), 2)|max(session_count)|\n",
      "+---------+------------------+----------------------------+------------------+\n",
      "|      112|                71|                       83.55|                97|\n",
      "|      113|                71|                       86.96|               103|\n",
      "|      130|                71|                       75.51|                80|\n",
      "|      126|                71|                       81.56|                93|\n",
      "|      149|                71|                       84.96|                99|\n",
      "|      110|                71|                       75.47|                80|\n",
      "|      136|                71|                       77.96|                85|\n",
      "|      144|                71|                       81.38|                92|\n",
      "|      116|                71|                       72.62|                75|\n",
      "|      145|                71|                       86.98|               103|\n",
      "|      143|                71|                        71.0|                71|\n",
      "|      107|                71|                       80.35|                90|\n",
      "|      146|                71|                       82.95|                95|\n",
      "|      103|                71|                       85.76|               101|\n",
      "|      139|                71|                       83.33|                96|\n",
      "|      114|                71|                       74.18|                78|\n",
      "|      115|                71|                        79.7|                89|\n",
      "|      104|                71|                       83.35|                96|\n",
      "|      120|                71|                       75.37|                80|\n",
      "|      128|                71|                       76.93|                83|\n",
      "+---------+------------------+----------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql('SELECT server_id, min(session_count), round(avg(session_count),2), max(session_count) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id')\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-default",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
